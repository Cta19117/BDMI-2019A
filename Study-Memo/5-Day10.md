#### 5-Day10

### Review

### Layer: Dense&CNN&RNN

neuron

tf.layers

batch_size

超参数 （网络结构决定）

输入输出的shape

#### Softmax

$$
Softmax(z_m)=\frac{e^{z_m}}{\sum_{k}{e^{z_k}}}
$$

#### Dense

tensorflow2.0文档，tf.layers.dense()

可以用于图像分类，但是参数量比较大

#### CNN

可以解决dense参数过多的问题

tf.layers.conv2d()

参数：filters ，kernel_size strides padding  ....

#### Pooling

采样，减少层神经元个数

#### Dropout

以一定的概率扔掉一些神经元

防止过拟合

#### RNN，LSTM

rnn层内神经元可影响下一个神经元

LSTM有门电路的结构，用于记忆，遗忘，输出

min-char-rnn 例子,如何不用库函数，写rnn

onehot结构

#### 创建github主页

profile

#### LSTM

读文章 understanding of LSTM

看tensorflow的代码

keras高层代码



















#### 

